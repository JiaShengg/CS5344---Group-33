## Tuning a Global Contamination Parameter

### Rationale for a Unified Global Contamination

Our ensemble model integrates multiple unsupervised anomaly detection algorithms, each trained on the same training set. These base models produce anomaly scores that are subsequently combined through rank normalization and weighted aggregation. However, different anomaly detection algorithms inherently assume different proportions of outliers in the data, as reflected by their default contamination parameters. This creates a fundamental misalignment: each model attempts to separate what it perceives as the "outlier fraction" from the rest of the data, but these fractions differ across models. To use an analogy, if each model is a pastry chef attempting to cut a cake with a different knife position, aggregating predictions from models with misaligned cutting points would be suboptimal.

We harmonize the ensemble by imposing a unified global contamination parameter across all base models. Aligning the assumption about the expected outlier proportion synchronizes the decision boundaries and improves the discriminative power of the fused scores. It is important to note, however, that contamination only affects a subset of the base learners. Distance- and density-based detectors such as Local Outlier Factor, COF, and KNN, isolation-based methods such as Isolation Forest, and several PyOD algorithms rely on the contamination setting to calibrate score thresholds or internal sampling. In contrast, RFOD produces scores independent of contamination. Enforcing a shared contamination therefore enables the models that do depend on the parameter to operate under a consistent prior while the others continue to contribute stable rankings—an essential precondition before rank-normalized fusion.

### Tuning Methodology

Our tuning procedure follows a grid-search routine: for each candidate contamination value, we train the full ensemble, obtain validation predictions, optimize model weights using a greedy search to maximize Average Precision (AP), and log the resulting validation AP. We evaluated contamination values in the range [0.01, 0.3] with a step size of 0.01. As illustrated in Figure X (to be inserted), the ensemble achieves its peak performance at a global contamination of 0.05, reaching a validation AP of approximately 0.47. This represents an improvement of approximately 4.4% relative to the baseline configuration without explicit contamination tuning (AP ≈ 0.45), or an absolute improvement of 0.02 AP points.

### Interpreting the 0.05 Optimum

The optimal contamination value of 0.05 may appear counterintuitive at first glance. The training set contains zero labeled positive samples, and the validation set has an anomaly rate of approximately 12.6%. Why, then, is the optimal contamination neither 0 (matching the training set) nor 0.126 (matching the validation set)? We argue that the optimal contamination is fundamentally a hyperparameter tuning outcome rather than a direct reflection of the dataset's class distribution.

Three factors explain this counterintuitive optimum. First, our aggregation pipeline applies rank normalization to all model predictions before weighted combination. Rank normalization transforms raw anomaly scores into percentile ranks, which mitigates the direct impact of contamination on score magnitudes. For many base models, contamination primarily affects decision thresholds or score scaling rather than the relative ordering of samples. After rank normalization, the influence of contamination becomes more subtle and model-specific—only certain models may exhibit sensitivity to contamination tuning, while others contribute relatively stable rankings regardless of the contamination parameter.

Second, setting contamination to match the training set's positive sample proportion (effectively zero, or approximated as 1e-6 in practice) would signal to one-class models that all samples are similar and no separation is necessary. This defeats the purpose of anomaly detection, as the models would fail to identify any meaningful outliers. The optimal contamination of 0.05, in contrast, instructs the models to identify and separate the most anomalous 5% of samples, pushing their scores further from the normal population. After rank normalization and aggregation, this translates to better discrimination: samples in roughly the top 5% of the ranked distribution (95th percentile and above) are effectively flagged as potentially anomalous, which logically accommodates the true anomaly rate (including zero in the training set) while maintaining sufficient separation for outlier identification. Empirically, this configuration demonstrates superior discriminative power on the validation set.

Third, during our model development process, we experimented with different feature combinations and ensemble compositions. Across these variations, the optimal global contamination values ranged from 0.01 to 0.10, demonstrating that contamination is not a fixed property of the dataset but rather a result of complex interactions between feature representations, model architectures, and aggregation strategies. This variability further supports the interpretation of contamination as a tuning parameter that shapes score distributions to optimize ranking performance, rather than a parameter that must match the true class distribution.

In summary, contamination serves as a hyperparameter that modulates score distributions to improve ranking quality, not as a parameter that must align with the observed anomaly rate. The fact that the test set has zero labeled anomalies does not invalidate our selection of 0.05 based on validation AP, as the parameter's role is to enhance the ensemble's ability to rank samples by anomaly likelihood, which is evaluated through the threshold-free Average Precision metric.
